---
title: "Time series example"
author: "JS"
output:
  html_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = TRUE, fig.height = 3)
```

Using the pulmonary model from the SECRET competition.

Load in design, data:

```{r, echo = FALSE, include=FALSE}
library(R.matlab)
library(ggplot2)
library(reshape2)
library(viridis)
library(cowplot)
library(fields)

setwd('~/Dropbox/UQ')
source('code/Gasp.R')
```


```{r}
design <- readRDS('data/designW1.rds')

t <- 512 # number of timepoints
v <- 3 # number of variables
n <- 100 # number of simulations

all_data <- array(0, dim = c(t,v,n))
for (i in 1:n){
  tmp <- readMat(paste0('data/output/flow', i, '.mat'))[[1]]
  all_data[,,i] <- tmp
}
```

Plot all data:

```{r}
plot_data <- data.frame(Time = 1:t,
                        Run = rep(1:n, each = t*v),
                        Output = c(all_data),
                        Type = rep(c('Flow1', 'Flow2', 'Pressure'), each = t))

plot_data2 <- melt(plot_data, id.vars = c('Time', 'Run', 'Type'))

ggplot(plot_data2, aes(x = Time, y = value, col = as.factor(Run))) +
  geom_line() +
  facet_wrap(vars(Type), nrow = 2, scales = 'free_y') +
  theme(legend.position = 'none')
```


## Emulate single output

Let's select timepoint 200 from Flow1 as our output. Creating dataframe, and plotting against 1 of the inputs:

```{r, fig.height=3}
design$ID <- NULL # don't need this column
tData <- data.frame(design[,1:4], y = all_data[200,1,])
head(tData)
ggplot(tData, aes(kMV, y)) + geom_point()
```

The inputs here are on very different scales. We should standardise these prior to modelling. Here, we have a fixed range for each input, so we use the min/max for each to scale these to [-1,1]:

```{r}
tData$kMV <- (tData$kMV - 9*10^4) / ((3*10^5 - 9*10^4)/2) - 1
tData$alpha <- (tData$alpha - 0.83) / ((0.89 - 0.83)/2) - 1
tData$lrrA <- (tData$lrrA - 20) / ((50 - 20)/2) - 1
tData$lrrV <- (tData$lrrV - 20) / ((50 - 20)/2) - 1
summary(tData)
```

We probably want to split into training/test sets at this point. We could do this manually, or we can handle this internally in the emulation code.

To do use this code, there's 1 more thing we need to do. From the notes in `Gasp.R`, the input data must have the structure [design, Noise, output]. This is because a noise term is used in the selection of a mean function:

```{r}
tData <- data.frame(tData[,1:4],
                    Noise = runif(nrow(tData), -1, 1),
                    y = tData$y)
```

Now we can run the code:

```{r}
em1 <- BuildGasp('y', tData)
summary(em1)
```

This has stored an rgasp emulator under `$em`, what mean function was used (here none, hence `NULL`), and also what the training data and validation data were. If you look at `Gasp.R` or the raw code for `BuildGasp`, you'll see there's an input `training_prop`, which will split the data into training and validation sets, with a default of 75\% used for training.

We can validate in several ways:

```{r}
par(mar = c(4,2,2,2));ValidateGasp(em1)
```

This function has several options. If you provide it with only an emulator, it will predict over the validation data stored in the `BuildGasp` object. You can alternatively provide it with a new dataset. You can also get it to plot the predictions against the inputs:

```{r}
par(mfrow = c(2,3), mar = c(4,2,2,2));ValidateGasp(em1, IndivPars = TRUE)
```

Alternatively, can do leave-one-out across the training data:

```{r}
par(mar = c(4,2,2,2));LeaveOneOut(em1)
```

This emulator seems reasonably good, but we could try something more complicated in the mean function. Could just do linear:

```{r}
em2 <- BuildGasp('y', tData, mean_fn = 'linear')
par(mfrow=c(1,2),mar = c(4,2,2,2));ValidateGasp(em2);LeaveOneOut(em2)
```

Or could fit something more general:

```{r, eval=FALSE}
em3 <- BuildGasp('y', tData, mean_fn = 'step')
```

```{r, include=FALSE}
em3 <- BuildGasp('y', tData, mean_fn = 'step')
```

```{r}
par(mfrow=c(1,2),mar = c(4,2,2,2));ValidateGasp(em3);LeaveOneOut(em3)
```

Here, we've fitted a more complicated mean surface initially - we have some new entries in our emulator:

```{r}
summary(em3)
```

`$lm` is a fitted linear regression object, giving more complex mean structure:

```{r}
summary(em3$lm$linModel)
```

`$active` is a list of which of the input variables are treated as active when fitting the GP to the residuals (essentially, in the mean fitting process we may find that some inputs are just noise, hence we don't include these when fitting the covariance):

```{r}
em3$active
```







## Emulate full output
