---
title: "Time series example"
author: "JS"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = TRUE, fig.height = 3)
```

Using the pulmonary model from the SECRET competition.

Load in design, data:

```{r, echo = FALSE, include=FALSE}
library(R.matlab)
library(ggplot2)
library(reshape2)
library(viridis)
library(cowplot)
library(fields)

setwd('~/Dropbox/UQ')
source('code/Gasp.R')
```


```{r}
design <- readRDS('data/designW1.rds')

t <- 512 # number of timepoints
v <- 3 # number of variables
n <- 100 # number of simulations

all_data <- array(0, dim = c(t,v,n))
for (i in 1:n){
  tmp <- readMat(paste0('data/output/flow', i, '.mat'))[[1]]
  all_data[,,i] <- tmp
}
```

Plot all data:

```{r}
plot_data <- data.frame(Time = 1:t,
                        Run = rep(1:n, each = t*v),
                        Output = c(all_data),
                        Type = rep(c('Flow1', 'Flow2', 'Pressure'), each = t))

plot_data2 <- melt(plot_data, id.vars = c('Time', 'Run', 'Type'))

ggplot(plot_data2, aes(x = Time, y = value, col = as.factor(Run))) +
  geom_line() +
  facet_wrap(vars(Type), nrow = 2, scales = 'free_y') +
  theme(legend.position = 'none')
```


## Emulate single output

Let's select timepoint 200 from Flow1 as our output. Creating dataframe, and plotting against 1 of the inputs:

```{r, fig.height=3}
design$ID <- NULL # don't need this column
tData <- data.frame(design[,1:4], y = all_data[200,1,])
head(tData)
ggplot(tData, aes(kMV, y)) + geom_point()
```

The inputs here are on very different scales. We should standardise these prior to modelling. Here, we have a fixed range for each input, so we use the min/max for each to scale these to [-1,1]:

```{r}
tData$kMV <- (tData$kMV - 9*10^4) / ((3*10^5 - 9*10^4)/2) - 1
tData$alpha <- (tData$alpha - 0.83) / ((0.89 - 0.83)/2) - 1
tData$lrrA <- (tData$lrrA - 20) / ((50 - 20)/2) - 1
tData$lrrV <- (tData$lrrV - 20) / ((50 - 20)/2) - 1
summary(tData)
```

We probably want to split into training/test sets at this point. We could do this manually, or we can handle this internally in the emulation code.

To use this code, there's 1 more thing we need to do. From the notes in `Gasp.R`, the input data must have the structure [design, Noise, output]. This is because a noise term is used in the selection of a mean function:

```{r}
tData <- data.frame(tData[,1:4],
                    Noise = runif(nrow(tData), -1, 1),
                    y = tData$y)
```

Now we can run the code (setting a seed for reproducibility, because this function will randomly split the data into training/validation):

```{r}
set.seed(2101)
em1 <- BuildGasp('y', tData)
summary(em1)
```

This has stored an rgasp emulator under `$em`, what mean function was used (here none, hence `NULL`), and also what the training data and validation data were. If you look at `Gasp.R` or the raw code for `BuildGasp`, you'll see there's an input `training_prop`, which will split the data into training and validation sets, with a default of 75\% used for training.

We can validate in several ways:

```{r}
par(mar = c(4,2,2,2));ValidateGasp(em1)
```

This function has several options. If you provide it with only an emulator, it will predict over the validation data stored in the `BuildGasp` object. You can alternatively provide it with a new dataset. You can also get it to plot the predictions against the inputs:

```{r}
par(mfrow = c(2,3), mar = c(4,2,2,2));ValidateGasp(em1, IndivPars = TRUE)
```

This emulator might not be suitable: these are 95\% prediction intervals, and we have 5/25 points coloured red, i.e. 20\% of our predictions are outside these intervals.

Alternatively, can do leave-one-out across the training data:

```{r}
par(mar = c(4,2,2,2));LeaveOneOut(em1)
```

We're doing a bit better here - have around 5\% outside 95\%. 

We could try something more complicated in the mean function. Could just do linear:

```{r}
set.seed(5820)
em2 <- BuildGasp('y', tData, mean_fn = 'linear')
par(mfrow=c(1,2),mar = c(4,2,2,2));ValidateGasp(em2);LeaveOneOut(em2)
```

Or could fit something more general:

```{r, eval=FALSE}
set.seed(3100329)
em3 <- BuildGasp('y', tData, mean_fn = 'step')
```

```{r, include=FALSE}
set.seed(3100329)
em3 <- BuildGasp('y', tData, mean_fn = 'step')
```

```{r}
par(mfrow=c(1,2),mar = c(4,2,2,2));ValidateGasp(em3);LeaveOneOut(em3)
```

This final emulator appears to validate better than the others. Here, we've fitted a more complicated mean surface initially - we have some new entries in our emulator object:

```{r}
summary(em3)
```

`$lm` is a fitted linear regression object, giving this more complex mean structure:

```{r}
summary(em3$lm$linModel)
```

`$active` is a list of which of the input variables are treated as active when fitting the GP to the residuals (essentially, in the mean fitting process we may find that some inputs are just noise, hence we don't include these when fitting the covariance):

```{r}
em3$active
```

Here, all 4 of the inputs are considered active, but in general, as the dimensionality of the input space increases, it's more common for this to be a subset of the inputs.

By default, this mean function is not allowed more terms than 0.1*number of training points. However, this won't always work, and option `maxdf` allows flexibility in this specification (e.g., we may find we overfitted the data and want to limit the number of terms being added, or we may find that 10\% is too restrictive and we need to add more).


## Emulate full output

The above emulated a single output, but this code could be used to emulate $\ell$ outputs by looping over different outputs.

Alternatively, we could use dimension reduction to simplify this task. Let's emulate Flow1. First, we want to construct a basis. This is easy to do (this function has a lot more flexibility than is usually needed, e.g., can do weighted SVD for general matrices):

```{r}
DataBasis <- MakeDataBasis(all_data[,1,])
summary(DataBasis)
dim(DataBasis$tBasis)
dim(DataBasis$CentredField)
```

By default, this function subtracts the ensemble mean, and then calculates the SVD across the (centred) data. `$Q` and `$Lambda` are only stored if this function is used for weighted SVD, hence are not returned here (and indeed, not required in future calculations).

Plotting the leading few vectors:

```{r}
q <- 9
plot_basis <- data.frame(Time = rep(1:t, q),
                         Vector = rep(1:q, each = t),
                         Weight = c(DataBasis$tBasis[,1:q]))
ggplot(plot_basis, aes(Time, Weight)) +
  geom_line() +
  facet_wrap(vars(Vector))
```

Generally we truncate this basis for some small $q$ (such that a large enough amount of variability has been explained and/or such that any later vectors are just noise, with no signal from the parameters).

```{r}
q <- ExplainT(DataBasis, vtot = 0.95)
q
```

Here, 4 vectors explain 95\% of the variability in the data. In practice, we might want to try emulating the 5th, 6th etc. to see if these are predictable, but let's just use the 1st 4 for now.

Alternatively, plot cumulative variance explained:

```{r}
vars <- lapply(1:n, function(k) VarExplained(DataBasis$tBasis[,1:k], DataBasis$CentredField))
```

```{r}
ggplot(data.frame(q = 1:n, Proportion = unlist(vars)), aes(x = q, y = Proportion)) +
  geom_line() +
  ylim(0,1)
```



Projecting the data onto the basis:

```{r}
Coeffs <- Project(data = DataBasis$CentredField, 
                  basis = DataBasis$tBasis[,1:q])
colnames(Coeffs)[1:q] <- paste("C",1:q,sep="")
summary(Coeffs)
```


```{r}
tDataC <- data.frame(tData[,1:4], # getting the scaled version from before
                     Noise = runif(n, -1, 1), 
                     Coeffs)
head(tDataC)
```

Now we can build emulators for these $q$ coefficients. We can do this simultaneously for all $q$ (as long as we're happy using the same assumptions for each). To make things consistent across each emulator, I'm going to define training/validation sets by hand, and then fit to the full training set by setting `training_prop = 1` (rather than allowing the function to do this split for me):

```{r}
set.seed(321)
inds <- sample(1:n, n)
train_inds <- inds[1:75]
val_inds <- inds[-c(1:75)]
train_data <- tDataC[train_inds,]
val_data <- tDataC[val_inds,]
```


```{r, eval = FALSE}
em_coeffs <- BasisEmulators(tDataC, q, mean_fn = 'step', maxdf = 5, training_prop = 1)
```

```{r, include=FALSE}
em_coeffs <- BasisEmulators(train_data, q, mean_fn = 'step', maxdf = 5, training_prop = 1)
```

The output here is now a list of $q$ emulator objects, e.g.

```{r}
summary(em_coeffs[[1]])
summary(em_coeffs[[2]])
```

Now in `ValidateGasp`, we need to provide the validation set (it's no longer internal to the `BasisEmulator` object):

```{r}
par(mfrow=c(2,2), mar=c(4,2,2,2))
ValidateGasp(em_coeffs[[1]], val_data)
ValidateGasp(em_coeffs[[2]], val_data)
ValidateGasp(em_coeffs[[3]], val_data)
ValidateGasp(em_coeffs[[4]], val_data)

par(mfrow=c(2,2), mar=c(4,2,2,2))
LeaveOneOut(em_coeffs[[1]]);LeaveOneOut(em_coeffs[[2]]);LeaveOneOut(em_coeffs[[3]]);LeaveOneOut(em_coeffs[[4]])
```


## Prediction

The validation plots above are performing prediction across the test data. In general, we can predict for any sets of inputs, for either a 1D emulator, or for a set of basis emulators. Doing so across a space-filling design in parameter space (here, we are still working in [-1,1]):

```{r}
ns <- 1000 # usually want more, but set low for speed
BigDesign <- 2*as.data.frame(randomLHS(ns, 4)) - 1 
colnames(BigDesign) <- colnames(design)[1:4]

Preds_1D <- PredictGasp(BigDesign, em3)
Preds_basis <- BasisPredGasp(BigDesign, em_coeffs)
```

These store slightly different things - in the 1D case, we get mean/sd/lower95/upper95 (the same as what `predict.rgasp` returns):

```{r}
summary(Preds_1D)
```

In the basis case, I only store `$Expectation` and `$Variance` (as this is all we need for history matching, and because prediction intervals can be derived from these, so don't want to store these if we have a lot of emulators):

```{r}
summary(Preds_basis)
```

Both of these objects are $ns \times q$ dimensional, where each row corresponds to an input we're predicting at, and each column corresponds to a basis vector:

```{r}
dim(Preds_basis$Expectation)
dim(Preds_basis$Variance)
```


## Reconstructing

From basis coefficients (whether given by projection, or predicted by an emulator), we can reconstruct a prediction of the original field.

Let's consider the runs from the validation set. First produce predictions for them:

```{r}
Preds_val <- BasisPredGasp(val_data, em_coeffs)
```

Let's just take the first run, and compare the mean/variance to the truth (in coefficient/projection space):

```{r}
data.frame(Truth = as.numeric(val_data[1,-c(1:5)]),
           Mean = Preds_val$Expectation[1,],
           Var = Preds_val$Variance[1,])
```

Plot the true run vs emulator reconstruction of it (still with the ensemble mean removed, as this will dominate):

```{r}
plot_data <- data.frame(Time = 1:t,
                        Truth = DataBasis$CentredField[,val_inds[1]],
                        Recon = Recon(Preds_val$Expectation[1,], DataBasis$tBasis[,1:q]))
plot_data2 <- melt(plot_data, id.vars = c('Time'))
ggplot(plot_data2, aes(Time, value, col = variable)) + geom_line()
```

Looks quite accurate (remember this run was not used for fitting the emulator).

Mean prediction by itself is not that informative, also sample from the emulators:

```{r}
em_samp <- matrix(0, t, 100)
for (s in 1:100){
  samp <- rnorm(q, 
                mean = Preds_val$Expectation[1,],
                sd = sqrt(Preds_val$Variance[1,]))
  rec <- Recon(samp, DataBasis$tBasis[,1:q])
  em_samp[,s] <- rec
}
```

```{r}
ggplot(plot_data2, aes(Time, value, col = variable)) + 
  geom_line(data = data.frame(Time = 1:t, value = c(em_samp), s = rep(1:100, each = t)), aes(Time, value, linetype = as.factor(s)), col = 'grey', alpha = 0.6) +
  geom_line(size = 1.25) +
  scale_linetype_manual(values = rep(1,100), guide = 'none')
```

Really, we should also add the uncertainty due to the discarded basis vectors - by truncating the basis after $q$ vectors, we know that we're not perfectly reconstructing the true simulations via the emulators, and need to acknowledge this additional variability. It is likely small relative to the variability we've explained (less than 5\%) but we should still account for it.

There's a function that will calculate this variance matrix, and we can sample from it:

```{r}
extra_var <- DiscardedBasisVariance(DataBasis, q)
extra_var_samples <- rmvnorm(100, rep(0, t), extra_var)
dim(extra_var_samples)

plot_samples <- data.frame(Time = 1:512,
                           epsilon = c(t(extra_var_samples)),
                           s = rep(1:100, each = t))

ggplot(plot_samples, aes(Time, epsilon, col = as.factor(s))) + 
  geom_line(alpha = 0.6) +
  theme(legend.position = 'none')
```

The above is 100 samples from the discarded vectors, and we have clear correlated structure in these (some of the later basis vectors are likely quite noisy, however these will have lower variance/eigenvalues, so are drowned out by the earlier, more structured, discarded vectors).

Adding this variability onto our emulator samples:

```{r}
ggplot(plot_data2, aes(Time, value, col = variable)) + 
  geom_line(data = data.frame(Time = 1:t, value = c(em_samp + t(extra_var_samples)), s = rep(1:100, each = t)), aes(Time, value, linetype = as.factor(s)), col = 'grey', alpha = 0.6) +
  geom_line(size = 1.25) +
  scale_linetype_manual(values = rep(1,100), guide = 'none')
```

Before, we were missing the data in places, because the truncated basis did not have the ability to perfectly reconstruct the truth. Now, the truth lies within our uncertainty.

Just plotting 95\% prediction intervals for clarity:

```{r}
plot_data <- data.frame(Time = 1:t,
                        Truth = DataBasis$CentredField[,val_inds[1]],
                        Recon = rep(Recon(Preds_val$Expectation[1,], DataBasis$tBasis[,1:q]), 2),
                        Lower = c(apply(em_samp, 1, quantile, probs = 0.025), apply(em_samp + t(extra_var_samples), 1, quantile, probs = 0.025)),
                        Upper = c(apply(em_samp, 1, quantile, probs = 0.975), apply(em_samp + t(extra_var_samples), 1, quantile, probs = 0.975)),
                        Type = rep(c('EmVar', 'FullVar'), each = t))
plot_data2 <- melt(plot_data, id.vars = c('Time', 'Type'))
pal <- scales::hue_pal()(2)
ggplot(plot_data2, aes(Time, value, col = variable, linetype = variable)) +
  geom_line(size = 0.8) +
  facet_wrap(vars(Type)) +
  scale_linetype_manual(values = c(1,1,2,2)) +
  scale_colour_manual(values = pal[c(1,2,2,2)]) +
  theme(legend.position = 'none')
```




Or doing for 4 different inputs (immediately adding in the variance from the discarded vectors):

```{r}
em_samp <- array(0, dim = c(t, 100, 4))
plot_data <- NULL
for (i in 2:5){
  plot_data <- rbind(plot_data,
                     data.frame(Time = 1:t,
                                Truth = DataBasis$CentredField[,val_inds[i]],
                                Recon = Recon(Preds_val$Expectation[i,], DataBasis$tBasis[,1:q]),
                                Run = i))
  for (s in 1:100){
    samp <- rnorm(q, 
                  mean = Preds_val$Expectation[i,],
                  sd = sqrt(Preds_val$Variance[i,]))
    rec <- Recon(samp, DataBasis$tBasis[,1:q])
    em_samp[,s,i-1] <- rec
  }
}

plot_data2 <- melt(plot_data, id.vars = c('Time', 'Run'))

extra_var_samples <- t(rmvnorm(400, rep(0, t), extra_var))
dim(extra_var_samples) <- c(t, 100, 4)

plot_data_samp <- data.frame(Time = 1:t, 
                             value = c(em_samp + extra_var_samples), 
                             s = rep(1:100, each = t),
                             Run = rep(2:5, each = t*100))

ggplot(plot_data2, aes(Time, value, col = variable)) +
  facet_wrap(vars(Run), scales = 'free_y') +
  geom_line(data = plot_data_samp, aes(Time, value, linetype = as.factor(s)), col = 'grey', alpha = 0.6) +
  geom_line(size = 0.8) +
  scale_linetype_manual(values = rep(1,100), guide = 'none')
```



